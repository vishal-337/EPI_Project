%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%


\documentclass[sigconf]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\settopmatter{printacmref=false}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{none}      % remove ACM rights/permissions text
\settopmatter{printacmref=false} % hide "ACM Reference Format"
\acmDOI{}                % clear DOI line
\acmISBN{}               % clear ISBN line
\acmPrice{}              % clear price line (if any)

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[]{}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Modeling the Opioid Prescription Epidemic as a Clinical Practice Contagion}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.




\author{Vishal Maradana}
\affiliation{%
  \institution{Georgia Institute of Technology}
  \city{Atlanta,GA}
  \country{United States}}
\email{vmaradana3@gatech.edu}

\author{Rishi Bandi}
\affiliation{%
  \institution{Georgia Institute of Technology}
  \city{Atlanta,GA}
  \country{United States}}
\email{rbandi6@gatech.edu}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
This project treats high-rate opioid prescribing as a behavior that may diffuse across U.S. states through professional norms, policy signals, and information flows. Using publicly available state-level dispensing data and policy timelines, we will infer a directed influence network among states, identify historically influential “spreaders,” and run what-if intervention simulations to estimate how targeted policies might have altered trajectories. We validate the approach against held-out years and interpret results alongside evidence on Prescription Drug Monitoring Programs (PDMPs).

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%





%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}

  \includegraphics[width=\textwidth]{opiod.png}
  \caption{Seattle Mariners at Spring Training, 2010.}
  \Description{Enjoying the baseball game from the third-base
  seats. Ichiro Suzuki preparing to bat.}
  \label{fig:teaser}
\end{teaserfigure}

\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Related Work}
Work on diffusion and influence in networks provides the conceptual and algorithmic backbone for our project. Kempe, Kleinberg, and Tardos\cite{Kempe2003KDD} formalized two now-canonical generative views of spread—the Independent Cascade (IC) and Linear Threshold (LT) models—and showed that choosing seed nodes to maximize downstream adoptions is NP-hard, but admits a tight greedy approximation because the expected influence function is submodular under IC and LT. Their formulation supplies two strengths we can leverage: (i) an explicit, step-by-step account of contagion dynamics (rather than a purely correlational view of co-occurrence), and (ii) a rigorous optimization lens with performance guarantees, which also clarifies why naïve structural heuristics (high degree, centrality) can perform poorly when they ignore redundancy and diminishing returns among targets. At the same time, the Kempe framework presumes a known network and focuses on forward optimization (who to seed) rather than inverse inference (who influenced whom), and their experiments rely on proxy graphs rather than observed transmission networks, leaving open how to recover influence structure from aggregated, real-world “adoption times.” These trade-offs motivate our emphasis on inferring a directed inter-state influence network from timing data before we evaluate targeting or simulate interventions.

That inverse problem is addressed directly by NETINF, which assumes many cascades propagate over an unobserved, static network and seeks the directed edges that best explain observed infection times \cite{GomezRodriguez2010NetInf}. Its central strengths are a generative likelihood over propagation trees and a scalable, near-optimal approximation to an otherwise intractable objective, demonstrated on massive web/media cascades where it recovers a core-periphery structure among news sites \cite{GomezRodriguez2010NetInf}. This establishes a rigorous bridge from when nodes adopt to which edges likely transmitted the contagion. For a public-health application like ours, however, NETINF’s assumptions matter: tree-structured cascades assign a single parent per adoption; networks are fixed; and multiple distinct contagions provide repeated evidence. In statewide opioid prescribing, we observe one annual outcome stream rather than many independent memes, and cyclical or reciprocal pathways are plausible. Consequently, we intend to adopt NETINF’s timing-to-edges intuition but favor a transparent, count-based construction (who was high before whom) that can trade some statistical efficiency for policy readability and robustness checks, while still rooting the approach in the cascade logic introduced by \cite{GomezRodriguez2010NetInf}.

Moving from algorithms to public-health networks, Kaminski et al. build a provider network for Indiana by projecting shared-patient (opioid co-prescription) ties and recovering data-driven professional communities with the Leiden algorithm \cite{Kaminski2023HRJ}. They compare these communities to administratively defined Public Health Preparedness Districts (PHPDs) and show that alignment varies substantially; in some regions the match is high, in others low, implying that district-based messaging can both overreach and miss key prescribers \cite{Kaminski2023HRJ}. The strength here is empirical specificity: rather than assuming geography captures influence, the paper demonstrates where clinical relationship networks suggest different targeting boundaries. A second strength is outcome relevance: they compare whether PHPDs or network communities better “concentrate” opioid-relevant indicators such as OUD diagnoses, MME, and overdose diagnoses, making the case that network-aware delivery may improve precision \cite{Kaminski2023HRJ}. The limitations for our setting are scope and dynamics. The analysis is single-state, clinician-level, and primarily cross-sectional/descriptive about where to target, not about the temporal mechanics of who crosses a behavioral threshold because of whom. Our work can complement \cite{Kaminski2023HRJ} by moving to the state level, reconstructing directed, time-ordered influence between jurisdictions, and then testing intervention timing scenarios.

O’Malley et al. deepen the mechanism story by quantifying risky-prescribing behaviors within shared-patient physician networks and by proposing supra-dyadic (triadic) statistics and non-parametric tests to detect homophily beyond pairs \cite{Ran2024ANS}. They also introduce physician-level state-transition indices—capturing both prescribing and deprescribing—to attribute responsibility and to construct node attributes for modeling \cite{Ran2024ANS}. Two strengths stand out for our project. First, they demonstrate that risky-prescribing homophily appears at the triadic level, not just dyads, with specialty assortativity and regional variation, suggesting that local norms and clustered structures help sustain behavior \cite{Ran2024ANS}. This substantiates our behavioral-contagion framing and cautions against interventions that focus solely on single “hubs.” Second, their pragmatic data engineering (transition matrices, deprescribing attribution) showcases how to extract policy-relevant signals from claims. Limitations relative to our aims include reliance on a single-year Medicare sample and focus on clinician-to-clinician ties without explicit counterfactual policy simulations. We plan to incorporate the lessons qualitatively—acknowledging clustering and multiple channels of reinforcement—while operating at the jurisdictional scale with multi-year trajectories and explicit “what-if” interventions.

Viewed together, these strands suggest a coherent path for our study. The diffusion mechanics and submodular perspective from \cite{Kempe2003KDD} clarify why targeting a small set of actors can be principled rather than heuristic and provide natural ablations to compare eigenvector-based targeting against simpler degree rules. The inverse-inference lens from \cite{GomezRodriguez2010NetInf} shows how adoption timing can reveal hidden edges, motivating our simpler but interpretable timing-aggregation network when only a single, annual behavioral cascade is available. The targeting mismatch highlighted by \cite{Kaminski2023HRJ} warns that geography is an imperfect proxy for influence; by elevating to the state level and building a directed influence graph, we can transpose their “communities vs. districts” insight into “influence pathways vs. borders,” asking which jurisdictions have historically nudged others over high-prescribing thresholds. The supra-dyadic clustering in \cite{Ran2024ANS} then argues for evaluating influential sets rather than singletons and for testing whether intervention effects persist when influence resides in tightly knit clusters rather than star-shaped hubs.

This synthesis also surfaces gaps we can address. First, while \cite{Kempe2003KDD} and \cite{GomezRodriguez2010NetInf} come with guarantees and likelihoods, respectively, their assumptions (known graph; many independent cascades; tree-structured diffusion) fit large online settings better than annual, macro-level clinical practice shifts. We will therefore keep the core logic—time-ordered spread and diminishing returns—but use a transparent construction with sensitivity analyses around thresholds and centrality choices. Second, whereas \cite{Kaminski2023HRJ} and \cite{Ran2024ANS} convincingly demonstrate that real clinical ties and homophily shape where and how prescribing clusters, neither paper links those structures to policy-timed counterfactuals at jurisdictional scale. Our contribution will be to anchor intervention timing in external policy chronologies while using a diffusion-consistent network to examine how targeting influential states at realistic dates might have changed the trajectory. Finally, all four lines of work implicitly caution against overclaiming causality: influence edges inferred from timing or topology reflect directional hypotheses, not proof. We will therefore position our results as hypothesis-generating but decision-relevant, with clear caveats and robustness checks.

The application of network and diffusion modelling to comprehend opioid prescribing behaviour and policy effects is still being expanded by recent work. By employing multiple detection algorithms and modularity maximisation to validate opioid agonist treatment prescriber networks built from administrative data, Kurz et al. (2025) showed that the resulting network "communities" reflected underlying clinical practice patterns rather than straightforward administrative or geographic boundaries. Using claims data to identify professional prescriber communities, Kaminski et al. (2023) demonstrated that network-based boundaries provide more precision for targeted interventions and that officially designated public health districts frequently do not align with actual influence structures. In their comparison of various centrality measures in bipartite patient-provider networks, \cite{Yang2022JBI} discovered that bipartite-aware indices perform better than conventional one-mode algorithms like PageRank in detecting high-risk drug-seeking behaviours and forecasting overdose, especially when incorporating drug potency measures like morphine milligramme equivalents (MME). In Rhode Island, related analyses also showed that patients clustered by opioid type, dosage level, and shared-provider ties, and that patterns of influence and diffusion were strongly predicted by both network centrality and homophily, particularly for patients receiving naloxone or buprenorphine treatments. When taken as a whole, these studies show that network-informed perspectives on clinical relationships can highlight significant borders and pathways of propagation that are missed by administrative or geographic units.

The mechanisms through which prescribing practices spread have been better understood thanks to parallel advancements in behavioural clustering and influence inference techniques. The prediction of overprescribing behaviours is improved and standard contagion models are given structural nuance by emerging dynamic graph neural network architectures like Dynamic Dual-Heterogeneous Graph Neural Networks (DDHGNN), which offer new methods for separating heterogeneous provider–patient data and capturing temporal dependencies. According to \cite{Kurz2025AddictResTheory}, risky-prescribing clusters frequently function at the triadic (three-node) level, where homophily and reinforcement go beyond pairwise ties. This supports the idea that diffusion within close-knit subgroups is maintained by local social and professional norms. Policy-focused assessments have also started to take advantage of network evidence: interventions at the prescriber and clinic levels have been demonstrated to result in quantifiable decreases in the prescription of opioids, and state-level analyses that integrate administrative and network data show decreases in overdose and misuse rates in cases where policies specifically targeted provider communities rather than single individuals. Early-risk identification and counterfactual simulation of intervention impacts are now supported by broader applications of big data analytics and social network analysis, indicating that state surveillance systems could incorporate network-based intelligence for more flexible policy design. Notwithstanding these advancements, there are still enduring obstacles concerning cross-state data integration and Prescription Drug Monitoring Program (PDMP) interoperability, which restrict the use of these network models in real-time for operational public health decision-making. All of these advancements highlight the necessity of data-driven, interpretable, and diffusion-aware frameworks, such as the one put forth here, that can connect methodological advancements with practical insights to reduce the overprescription of opioids.


\section{Problem Definition}
We aim to test whether high opioid prescribing behaves like a practice that spreads across U.S. states through professional and policy influence rather than arising independently. In everyday terms, when one state’s prescribing stays high, socially or institutionally connected states may be more likely to become high later; if that’s true, focusing on a few pivotal states could shift the national trajectory. Formally (in words), we will treat each state as a node with an annual prescribing rate and define the first year a state enters a “high” category using transparent, CDC-anchored cutoffs. From the year-to-year ordering of these entries, we will infer a directed, weighted influence network that summarizes who tended to precede whom, produce a ranking of influential states, and simulate policy scenarios in which selected states no longer propagate influence after realistic start years.
\section{Techniques}
We will build an interpretable influence graph directly from timing. For each year, if State A is already in the “high prescribing” category and State B newly enters that category the following year, we record a plausible A→B influence event. Aggregating these events across the timeline yields directed edges with strengths proportional to their empirical support. To reduce noise, we will prune edges that occur rarely relative to their opportunities, test multiple “high” thresholds anchored to CDC reporting, and bootstrap years to produce uncertainty bands on edge strengths. The result is a transparent, policy-readable network that captures who tended to precede whom.

On the inferred graph, we will rank states primarily using eigenvector centrality, which rewards nodes connected to other influential nodes and is well-suited to cascading behaviors. To check robustness and interpretability, we will compare rankings against degree (simple, exposure-based) and betweenness (bridge-based) centralities, noting where measures agree or diverge. We will report stable top-k sets across thresholds, edge-support cutoffs, and bootstrapped graphs. This triangulation guards against overreliance on any single metric and yields a defensible short list of states that plausibly amplify or relay high-prescribing practices through the network.

We will simulate trajectories on this network to compare a baseline with targeted interventions. The baseline initializes with states observed “high” in an early year and advances year by year, allowing susceptible states to activate based on incoming edge strengths. Intervention runs convert selected top-ranked states to non-influential from policy-plausible years onward (e.g., aligned with PDMP mandates) and re-simulate. We will summarize outcomes as annual counts of high states, overlap with historical high-state sets, and differences between baseline and intervention curves, with uncertainty from bootstrap replicates.
\section{Evaluation plan}
We will judge the approach on its ability to replay and sensibly extend history, not just fit it. First, we will train the influence network on an early slice of the series and then simulate the subsequent period, comparing the trajectory of high-prescribing states against what actually happened. Accuracy will be summarized with straightforward error measures and with set overlap between simulated and observed high states each year. To avoid flattering comparisons, we will use simple baselines: a carry-forward trend with no network and an independent per-state model that ignores cross-state influence. Robustness will be checked by varying the threshold that defines “high,” pruning weak edges with little support, swapping the centrality metric used for targeting, and shifting the initialization window; we will report where conclusions stay stable and where they do not. Uncertainty will be shown with bootstrap resampling so readers can see plausible ranges, not just single lines. For policy realism, intervention start years will be aligned with documented policy timelines, and we will discuss where simulated changes line up with the literature and where they diverge. Success means lower error than baselines, stable influential-state rankings across reasonable choices, and intervention curves that are consistent with policy timing and domain knowledge.
\section{Data}
We will use CDC’s state-level Opioid Dispensing Rate Maps as our outcome series: annual prescriptions per 100 persons for each U.S. state, provided as web tables with downloadable files. This yields a tidy state-year panel covering the mid-two-thousands through recent years, suitable for defining “high” prescribing and for building adoption timelines.Data are provided as web tables with downloadable files (CSV/Excel).\href{https://www.cdc.gov/overdose-prevention/data-research/facts-stats/opioid-dispensing-rate-maps.html}{[link]}

For policy timing and interpretation, we will use the Prescription Drug Abuse Policy System (PDAPS) legal datasets on PDMP Implementation Dates (enactment, operation, access) and companion PDMP law tables on Reporting and Authorized Use and Access and Registration.These are downloadable, research-ready spreadsheets with clear variable definitions for all states.\href{https://pdaps.org/datasets/prescription-monitoring-program-laws-1408223416-1502818373}{link}
\section{implementation plan}
There are five main stages in this project's implementation plan: Data Acquisition & Pre-processing will download PDAPS policy data and CDC prescribing rates, determine the first year of adoption, and use explicit thresholds to define each state's annual "high prescribing" status. Then, using edge pruning and bootstrapping for robustness, Network Inference will create a directed, weighted influence network by combining cases in which a state that is already "high" comes before a state that is just joining the "high" category. Eigenvector Centrality and other comparative metrics will be used in the third phase, State Ranking & Selection, to determine a stable, top-k group of historically significant "spreader" states. After establishing a baseline trajectory for the spread, the fourth phase, Intervention Simulation, will run counterfactual scenarios in which the top k states stop propagating from years onwards that are policy-plausible. To create decision-relevant hypotheses regarding how specific policies might have changed the course of the epidemic, Evaluation & Interpretation will lastly validate the model against held-out historical years, compare results against simpler baselines, and examine the intervention curves against policy timelines.











%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{name}


%%
%% If your work has an appendix, this is the place to put it.
\appendix


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
